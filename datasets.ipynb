{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_labeled_lpu = r'D:\\Veeple\\IT\\Python_scripts\\Scripts\\Обучение aidar_musin\\инфа из Согласия\\Список_ЛПУ_labeled.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lpu_labeled = pd.read_csv(path_to_labeled_lpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lpu_labeled['label'] = df_lpu_labeled['label'].apply(json.loads)\n",
    "df_lpu_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_lpu_dataframe(df):\n",
    "    transformed_data = []\n",
    "\n",
    "    for text, labels in zip(df[\"text\"], df[\"label\"]):\n",
    "        extracted_entities = []\n",
    "\n",
    "        for entity in labels:\n",
    "            entity_type = entity[\"labels\"][0]  # Берем первый тип сущности\n",
    "            extracted_entities.append({\n",
    "                \"type\": entity_type,\n",
    "                \"text\": entity[\"text\"],\n",
    "                \"start\": entity[\"start\"],\n",
    "                \"end\": entity[\"end\"]\n",
    "            })\n",
    "\n",
    "        transformed_data.append({\n",
    "            \"address\": text,\n",
    "            \"extracted_entities\": extracted_entities\n",
    "        })\n",
    "\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result = transform_lpu_dataframe(df_lpu_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "logging.info(f\"using device: {device}\")\n",
    "\n",
    "address_ner_pipeline = pipeline(\"ner\", model=\"aidarmusin/address-ner-ru\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_address(address):\n",
    "    entities = address_ner_pipeline(address)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_5000lpu = r'D:\\Veeple\\IT\\Python_scripts\\Scripts\\Обучение aidar_musin\\инфа из Согласия\\Список_ЛПУ.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(path_to_5000lpu)\n",
    "df = df[['Адрес ЛПУ']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Адрес ЛПУ_aidared'] = df['Адрес ЛПУ'].apply(process_address)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_subtokens(entities, address):\n",
    "    \"\"\"\n",
    "    Объединяет субтокены в цельные слова, используя оригинальный текст из address.\n",
    "    \"\"\"\n",
    "    merged_entities = []\n",
    "    current_entity = None\n",
    "\n",
    "    for entity in entities:\n",
    "        entity_type = entity['entity'].replace(\"B-\", \"\").replace(\"I-\", \"\")  # Убираем B- и I-\n",
    "        start, end = entity[\"start\"], entity[\"end\"]\n",
    "\n",
    "        if entity['entity'].startswith(\"B-\") or current_entity is None or current_entity[\"type\"] != entity_type:\n",
    "            # Если новый B-тег или тип сущности изменился, начинаем новую сущность\n",
    "            if current_entity:\n",
    "                merged_entities.append(current_entity)  # Сохраняем предыдущую сущность\n",
    "            current_entity = {\n",
    "                \"type\": entity_type,\n",
    "                \"text\": address[start:end],  # Берём оригинальный текст\n",
    "                \"start\": start,\n",
    "                \"end\": end\n",
    "            }\n",
    "        else:\n",
    "            # Продолжаем текущую сущность\n",
    "            current_entity[\"end\"] = end  # Обновляем конец\n",
    "            current_entity[\"text\"] = address[current_entity[\"start\"]:end]  # Берём текст заново\n",
    "    \n",
    "    if current_entity:\n",
    "        merged_entities.append(current_entity)  # Добавляем последнюю сущность\n",
    "\n",
    "    return merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataframe(df):\n",
    "    \"\"\"\n",
    "    Преобразует датафрейм в нужный формат.\n",
    "    \"\"\"\n",
    "    transformed_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        address = row[\"Адрес ЛПУ\"]\n",
    "        if isinstance(address, list):\n",
    "            address = \", \".join(address)  # Соединяем через запятую\n",
    "\n",
    "        extracted_entities = merge_subtokens(row[\"Адрес ЛПУ_aidared\"], address)\n",
    "        \n",
    "        transformed_data.append({\n",
    "            \"address\": address,\n",
    "            \"extracted_entities\": extracted_entities\n",
    "        })\n",
    "    \n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_result = transform_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataset = old_result[:2500].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = new_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_dataset = old_dataset + new_dataset\n",
    "mixed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение в файл\n",
    "with open(\"mixed_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mixed_dataset, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
